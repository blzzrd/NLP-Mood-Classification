{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Musical Emotion Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-Ce24o9HfmM"
      },
      "source": [
        "#Musical Emotion Classification using Lyrical Analysis\n",
        "---\n",
        "Alejandro Castaneda [cas29@pdx.edu]\n",
        "Jacob Klusnick [klusnick@pdx.edu]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3Oh0ZEhmlWq"
      },
      "source": [
        "# **Data Collection**\n",
        "\n",
        "Due to copyright issues, MoodyLyrics can only provide the song title, artist, and the valence-arousal feedback. **No lyrics are available.** To work around this for our project, we need to scrape the internet for lyrics to perform analysis.\n",
        "\n",
        "Thanks to [John W Millr](https://github.com/johnwmillr), we're able to use a Library to utilize Genius' API.\n",
        "\n",
        "The below installs the LyricsGenius Library. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5isokuRCryU",
        "outputId": "5607588c-d91b-40e5-c4bb-f0c00b53a668"
      },
      "source": [
        "!pip install git+https://github.com/johnwmillr/LyricsGenius.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/johnwmillr/LyricsGenius.git\n",
            "  Cloning https://github.com/johnwmillr/LyricsGenius.git to /tmp/pip-req-build-t3prw_vx\n",
            "  Running command git clone -q https://github.com/johnwmillr/LyricsGenius.git /tmp/pip-req-build-t3prw_vx\n",
            "Requirement already satisfied (use --upgrade to upgrade): lyricsgenius==3.0.0 from git+https://github.com/johnwmillr/LyricsGenius.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: beautifulsoup4>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from lyricsgenius==3.0.0) (4.6.3)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from lyricsgenius==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->lyricsgenius==3.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->lyricsgenius==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->lyricsgenius==3.0.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->lyricsgenius==3.0.0) (3.0.4)\n",
            "Building wheels for collected packages: lyricsgenius\n",
            "  Building wheel for lyricsgenius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lyricsgenius: filename=lyricsgenius-3.0.0-cp37-none-any.whl size=44717 sha256=4d396ad8eb18aa9d0dc056b9e239fb7809b5810f5eb2ad25fc5cfd81e4b1bd59\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c8j0guop/wheels/4c/c2/c2/711389881353cc8ef2f0055a712da5db9637132bc10151212e\n",
            "Successfully built lyricsgenius\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS2Aikg6yaBy",
        "outputId": "aaf6ec48-4e16-49fe-c987-39a85861d7a8"
      },
      "source": [
        "# Imports for translating from Genius to a JSON \n",
        "from lyricsgenius import Genius\n",
        "from google.colab import files\n",
        "\n",
        "import csv\n",
        "import json\n",
        "\n",
        "# Imports for the Model\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder\n",
        "\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWeEMomtO9rk"
      },
      "source": [
        "The below code requires a **client access token** for the Genius API. Populate your own access token in the first line. \n",
        "\n",
        "The below connects the GeniusLyrics Library with an interface for our own data collection, handling any potential misuse of the API and storing that into an error file, or a data file respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKzXb4-hmlBM"
      },
      "source": [
        "client_access_token = \"insert your token here.\"\n",
        "\n",
        "def get_lyrics(artist_name, song_title):\n",
        "  '''\n",
        "  get_lyrics will take an artist (string) and a song title (string), \n",
        "  and return the lyrics for that song (string) (if it is found). \n",
        "  '''  \n",
        "  genius = Genius(client_access_token)\n",
        "  genius.remove_section_headers = True\n",
        "  genius.verbose = False\n",
        "  artist = genius.search_artist(artist_name, max_songs=1, sort=\"title\", include_features=True)\n",
        "  if artist == None: \n",
        "    return None\n",
        "\n",
        "  song = artist.song(song_title)\n",
        "  if song == None:\n",
        "    return None\n",
        "\n",
        "  return song.lyrics"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTwgmGddTUrc"
      },
      "source": [
        "def gatherData(moodyLyricsFile, dataFileName, errorFileName):\n",
        "  songs = [] \n",
        "  invalid = []\n",
        "\n",
        "  with open(moodyLyricsFile) as csvf:\n",
        "    reader = csv.reader(csvf, delimiter=',')\n",
        "    headers = True\n",
        "    i = 0\n",
        "    for row in reader:\n",
        "      if headers:\n",
        "        headers = False\n",
        "        continue\n",
        "      \n",
        "      artist = row[1]\n",
        "      song = row[2]\n",
        "      label = row[3]\n",
        "\n",
        "      # do a try catch while loop so that it catches exceptions and keeps trying.\n",
        "      while True:\n",
        "        try:\n",
        "          lyrics = get_lyrics(artist, song)\n",
        "          break\n",
        "        except:\n",
        "          print(\"error with \" + song)\n",
        "\n",
        "      if lyrics == None:\n",
        "        invalid.append({'artist': artist, 'song': song}) \n",
        "      else:\n",
        "        songs.append({'artist': artist, 'song': song, 'lyrics': lyrics, 'label': label}) \n",
        "\n",
        "      print(f\"{i} song retrieved.\")\n",
        "      i += 1\n",
        "\n",
        "  with open(dataFileName, 'w') as lyr:\n",
        "    print(f\"{len(songs)} songs were added to the Lyrics.\")\n",
        "    json.dump(songs, lyr)\n",
        "  with open(errorFileName, 'w') as err:\n",
        "    print(f\"There were {len(invalid)} invalid songs.\")\n",
        "    json.dump(invalid, err)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWnprSf44DJ1"
      },
      "source": [
        "## Critical Information:\n",
        "If you do not have the lyrics as a JSON for the following code, uncomment lines 4 & 5 below and run the program. Note that it takes a couple hours to run through and collect the data. Keep the Notebook active during that time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpMbrGd0uWFZ"
      },
      "source": [
        "moodyLyricsFile = 'ml_raw.csv'\n",
        "outputJson = 'lyrics.txt'\n",
        "# --- Uncomment below ---\n",
        "#gatherData(moodyLyricsFile, outputJson, 'errors.txt')\n",
        "#files.download(outputJson)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5tdgcYIyt_m"
      },
      "source": [
        "# The Model\n",
        "\n",
        "The below code features a few helper functions to process the data, help with one-hot encoding on the y-axis (hence, LabelBinarizer, and train / test a neural network on the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCxEGQhKyCb9"
      },
      "source": [
        "def classify_song(label):\n",
        "  # For MultiLabelBinarizer, we specifically just want the index\n",
        "  # of whatever the song is at. This function is used to return\n",
        "  # thet index of the label. \n",
        "  labels = ['relaxed', 'angry', 'sad', 'happy']\n",
        "  return labels.index(label)\n",
        "\n",
        "def tag_pos(text):\n",
        "  # This function tags each set of text with NLTK's pos_taggers\n",
        "  # then returns the words as a unique string like 'word_TAG'.\n",
        "  token = nltk.word_tokenize(text)\n",
        "  return ' '.join([w+'_'+t for w, t in nltk.pos_tag(token)])\n",
        "\n",
        "def preprocess_data(data, mlb):\n",
        "  # This function gathers all the data and splits it into two \n",
        "  # arrays, X (lyrics) and Y (labels).\n",
        "  lyrics = []\n",
        "  labels = []\n",
        "  for song in data:\n",
        "    # We don't want songs with more than 10k characters in.\n",
        "    # Sorry musicals...\n",
        "    if len(song['lyrics']) > 10000: \n",
        "      continue\n",
        "    \n",
        "    lyrics.append(song['lyrics'])  \n",
        "    labels.append([song['label']])\n",
        "  # One-Hot Encoding tutorial taken from [3]\n",
        "  x = np.array(lyrics, dtype=object)\n",
        "  y = mlb.fit_transform(labels)\n",
        "  return x, y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWIzVUmxcOSM"
      },
      "source": [
        "With all the helper functions out of the way, we can load up the data and run it through a POS Tagger, Count Vectorizer, MLP Classifier, and assess the Neural Network. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKm4ePXey0IJ"
      },
      "source": [
        "with open('lyrics.txt', 'r') as jf:\n",
        "  data = json.load(jf)\n",
        "\n",
        "# Create the Multi Label Binarizer (and keep for inverse data later)\n",
        "# Load the data into x and y arrays\n",
        "mlb = MultiLabelBinarizer()\n",
        "x, y = preprocess_data(data, mlb)\n",
        "\n",
        "# Split and Shuffle the arrays\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
        "\n",
        "# Create a pipeline that POS-tags then vectorizes all the words\n",
        "# then run it through a MLP Classifier\n",
        "pipeline = Pipeline([\n",
        "  ('vect', CountVectorizer(preprocessor=tag_pos)),\n",
        "  ('nn', MLPClassifier())                   \n",
        "])\n",
        "\n",
        "# And perform 10-cross validation on it.\n",
        "gscv = GridSearchCV(pipeline, { }, cv=10)\n",
        "\n",
        "# Fit to the training data\n",
        "gscv.fit(x_train, y_train)\n",
        "\n",
        "# Test the results.\n",
        "y_pred = gscv.predict(x_test)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfSLs0WlzP_l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fd42304-18de-4e9f-f68b-20b60a708435"
      },
      "source": [
        "# reference, for 0, 1, 2, 3: \n",
        "labels = ['relaxed', 'angry', 'sad', 'happy']\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=labels))\n",
        "\n",
        "print(multilabel_confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     relaxed       0.91      0.62      0.74       134\n",
            "       angry       0.96      0.80      0.87       189\n",
            "         sad       0.94      0.68      0.79       158\n",
            "       happy       0.93      0.64      0.76       130\n",
            "\n",
            "   micro avg       0.94      0.70      0.80       611\n",
            "   macro avg       0.93      0.69      0.79       611\n",
            "weighted avg       0.94      0.70      0.80       611\n",
            " samples avg       0.69      0.70      0.69       611\n",
            "\n",
            "[[[469   8]\n",
            "  [ 51  83]]\n",
            "\n",
            " [[415   7]\n",
            "  [ 38 151]]\n",
            "\n",
            " [[446   7]\n",
            "  [ 50 108]]\n",
            "\n",
            " [[475   6]\n",
            "  [ 47  83]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nym_0r9axrI"
      },
      "source": [
        "The below pulls some examples using our models and performs an inverse transform to see what the classification of each song is. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPmpGBaULV9X",
        "outputId": "4ea62e8b-d5f0-409a-ff85-a4ebbeadb6e2"
      },
      "source": [
        "result = gscv.predict([get_lyrics('The Beatles', 'Happiness is a Warm Gun' )])\n",
        "print(mlb.inverse_transform(result))\n",
        "\n",
        "result = gscv.predict([get_lyrics('Ariana Grande', 'pete davidson' )])\n",
        "print(mlb.inverse_transform(result))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('angry',)]\n",
            "[('happy',)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtHln36xr38i"
      },
      "source": [
        "# References\n",
        "\n",
        "[1] Agrawal Y., Shanker R. G. R., Alluri V. (2021). Transformer-based approach towards music emotion recognition from lyrics. Institute of Information Technology, Hyderabad, India. \n",
        "\n",
        "[2] Çano, E., & Morisio, M. (2017). MoodyLyrics: A Sentiment Annotated Lyrics Dataset. Proceedings of the 2017 International Conference on Intelligent Systems, Metaheuristics & Swarm Intelligence - ISMSI '17. doi:10.1145/3059336.3059340\n",
        "\n",
        "\n",
        "\n",
        "[3] Kite. How to do One Hot Encoding with Numpy in Python. Retrieved from: https://www.kite.com/python/answers/how-to-do-one-hot-encoding-with-numpy-in-python "
      ]
    }
  ]
}